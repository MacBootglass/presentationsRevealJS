<section>
  <section>
    <h2>Applications</h2>
  </section>

  <section>
    <h3>Tracking d'objets en temps réél</h3>
    <img src="https://www.researchgate.net/profile/Sangkyu_Kang/publication/222655294/figure/fig3/AS:305187710357508@1449773828649/Fig-6-Model-fitting-procedure-of-NPT-AFM-a-optical-flow-based-feature-tracking-at.png" alt="exampleObjectTracking">
    <div class="italic">Exemples de tracking vidéo à partir des flux optiques</div>
  </section>

  <section>
    <img src="https://cdn.meme.am/cache/instances/folder782/62731782.jpg" alt="demonstrationMeme4">
  </section>

  <section>
    <h3>Navigation de drones</h3>
    <div class="colG">
      <div class="text">Utilisation des flux optiques pour éviter des obstacles, réguler la vitesse ou l'altitude.</div>
      <img style="width: 90%; float: left" src="https://i.ytimg.com/vi/V4r2HXGA8jw/hqdefault.jpg" alt="exampleDrone">
    </div>
    <div class="colD">
      <div class="text">
        Inspiration des travaux effectués sur la mouche et l’abeille: leur mode de vision repose sur le flux optique issu d’un capteur omnidirectionnel.
        Il est utilisé en simulation pour mettre en œuvre des capacités de stabilisation de trajectoire, d’évitement d’obstacles, de contrôle d’altitude et de suivi de terrain.
      </div>
    </div>
  </section>
  <section>
    <iframe width="960" height="500" src="https://www.youtube.com/embed/V4r2HXGA8jw" frameborder="0" allowfullscreen></iframe>
    <div class="italic">Exemple de rendu obtenu à partir de flux optiques pour la navigation d'un drone</div>
  </section>

  <section>
    <h3>Segmentation</h3>
  </section>
</section>
